## 目錄
* [目錄](#目錄)
* [基本說明](#基本說明)
* [SUSE 15 安裝示範](#SUSE-15-安裝示範)
* [網路設定](#網路設定)
* [NFS](#NFS)
* [NIS](#NIS)
* [chrony](#chrony)
* [munge](#munge)
* [slurm](#slurm)

---
## 基本說明
1. 主要紀錄本次架設時進行的設定操作，其餘較詳細的部分可以參考先前筆記
2. 


---
## SLES 15 安裝過程示範
0. 較為詳細的安裝過程請參考>>>[02. SUSE 15 Install.md](https://github.com/HongScarlet/homework/blob/master/SUSE15%20cluster/02.%20SUSE%2015%20Install.md) 
1. bios 關掉 Hyper Threading

2. 硬碟分割參考
```bash
# xeon
sda
├─sda1  512MB  /boot
├─sda2  192GB  [SWAP]
├─sda3   30GB  /
├─sda4     1K  
├─sda5   30GB  /usr
└─sda6  other  /tmp
```
```bash
# gpu (做lvm)
sda
├─sda1         512MB  /boot
└─sda2
  ├─vg00-lv00    2GB  [SWAP]
  └─vg00-lv01  256GB  /
```

---
## 網路設定

---
## NFS
server
```bash
server :~ # yast
Network Services > NFS Server
# Enter NFSv4 domain name

Host Wild Card  Options
192.168.1.0/24  rw,no_root_squash,async,no_subtree_check
client :~ # mkdir work1 work2
client :~ # yast
```

client
```bash
# 掛載 work1 work2 home
client :~ # mkdir work1 work2
client :~ # yast
Network Services > NFS Client

# 掛載repo
client :~ # zypper rr -a
client :~ # cd /work1/pkg/sle15sp2_repo/
client :~ # ls -d {M,P}* | xargs -i zypper ar {} {}
client :~ # zypper ref
client :~ # zypper lr
```

---
## NIS
server
```bash
server :~ # yast
Network Services > NIS Server

# NIS Domain Name
# Slave

Netmask        Network 
255.0.0.0      127.0.0.0  
255.255.255.0  192.168.1.0 

server :~ # systemctl enable ypserv
server :~ # systemctl start ypserv
server :~ # systemctl status ypserv
server :~ # ps aux | grep ypserv
```

client
```bash
client :~ # yast
Network Services > NIS Client
# NIS Domain
# Addresses of NIS servers

client :~ # systemctl enable ypbind
client :~ # systemctl start ypbind
client :~ # systemctl status ypbind
client :~ # ps aux | grep ypbind
```

test
```bash
server :~ # useradd test1
server :~ # getent passwd
test1:x:1001:100::......
client :~ # getent passwd
(找不到test1)

● yast > Network Services > NIS server
● 原因： 當server創建新user時,ypserv的資料沒有被更新,導致ypbind拿過去的資料沒有新user
● 因此直接重啟 ypserv 的服務是沒有用的
● yast > NIS server 完成設定後的第一步為 Remove /var/yp/jjc (移除舊的檔案後續在創建新的)

server:~ # cd /var/yp; make
```

```bash
client :~ # getent passwd
client :~ # id test1
(getent passwd 有抓到使用者，但id沒有)

client :~ # reboot
```

---
## chrony
```bash
clien :~ # vi /etc/chrony.conf
server <server ip>
client :~ # systemctl enable chronyd
client :~ # systemctl start chronyd
client :~ # chronyc sources
client :~ # chronyc burst 4/4
client :~ # chronyc makestep

# check
server :~ # date
client :~ # date
```

---
## munge
server
```bash
server :~ # zypper in munge
server :~ # systemctl enable munge
server :~ # systemctl start munge
```
client
```bash
server :~ # zypper in munge
server :~ # systemctl enable munge
server :~ # systemctl start munge
```
munge.key
```bash
server :~ # scp /etc/munge/munge.key root@<client>:/etc/munge/.
server :~ # md5sum /etc/munge/munge.key
client :~ # md5sum /etc/munge/munge.key
```
check
```bash
server :~ # munge -n
server :~ # munge -n | unmunge
server :~ # munge -n | ssh <client> unmunge

client :~ # munge -n
client :~ # munge -n | unmunge
client :~ # munge -n | ssh <server> unmunge
```


---
## slurm
install
```bash
# server
server :~ # zypper in slurm
server :~ # systemctl enable slurmctld
server :~ # systemctl start slurmctld
server :~ # systemctl status slurmctld

# client
client :~ # zypper in slurm-node
client :~ # systemctl enable slurmd
client :~ # systemctl start slurmd
client :~ # systemctl status slurmd

● client 上 slurmd.service 等 slurm.conf 設定完成後再進行啟用
```

port
```bash
# server
linux :~ # firewall-cmd --add-port=6819/tcp --add-port=6818/tcp --add-port=6817/tcp --permanent
linux :~ # firewall-cmd --reload
● slurmctld: 6817/tcp
● slurmd: 6818/tcp
● slurmdbd: 6819/tcp
```

slurm_conf
```bash
# ClusterName
ClusterName=<cluster>                                 # ClusterName (設定 QOS 時的 ClusterName必須和這邊相同)

# BackupServer                                        # 利用 backup 功能創建2個server
SlurmctldHost=s0(192.168.1.1)                         # server 0
SlurmctldHost=s1(192.168.1.2)                         # server 1
ReturnToService=2                                     # 0: down -> idle*  1: down -> down  2: down -> idle

# port config
SlurmctldPort=6817
SlurmdPort=6818
SrunPortRange=60001-63000                             # listening ports to communicate

# User
SlurmdUser=root
SlurmUser=root

# PID
SlurmctldPidFile=/var/run/slurm/slurmctld.pid
SlurmdPidFile=/var/run/slurm/slurmd.pid

# Debug
SlurmctldDebug=debug
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdDebug=debug
SlurmdLogFile=/var/log/slurm/slurmd.log

# for slurm DB
JobCompType=jobcomp/none
JobAcctGatherType=jobacct_gather/cgroup
AccountingStorageHost=s0
AccountingStoragePort=6819
AccountingStorageUser=slurm
AccountingStoragePass=/var/run/munge/munge.socket.2

# QOS Priority Weight
AccountingStorageEnforce=limits
PriorityWeightQOS=1000                                # 此數值預設為0，若數值為0，則不啟用PriorityWeight

# Node config
# gpu
GresTypes=gpu,mps
NodeName=g01 State=idle Gres=gpu:4,mps:400 Sockets=1 CoresPerSocket=8
NodeName=g02 State=idle Gres=gpu:4 Sockets=1 CoresPerSocket=8
...

# xeon32
NodeName=s01 State=idle Sockets=2 CoresPerSocket=16
NodeName=s02 State=idle Sockets=2 CoresPerSocket=16
...

# xeon
NodeName=e01 State=idle Sockets=2 CoresPerSocket=8
NodeName=e02 State=idle Sockets=2 CoresPerSocket=8
...

# Partition config
PartitionName=xeon Nodes=e08 Default=YES MaxTime=24:00:00 State=UP
PartitionName=xeon32 Nodes=s[01-05] MaxTime=96:00:00 State=UP
PartitionName=gpu Nodes=g[01-05] MaxTime=144:00:00 State=UP
...













# 安裝過程會經歷以下7個步驟(主要重點在5)
You will complete the following steps:
   1.  Welcome
   2.  End User License Agreement
   3.  Intel® Software Improvement Program
   4.  License Activation
   5.  Configuration
   6.  Installation
   7.  Installation Complete


